{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rock Paper Scissors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "# For Google Colab only: Selecting Tensorflow v2\n",
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.6\n",
      "Tensorflow version: 2.1.0\n",
      "Keras version: 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import platform\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "print('Python version:', platform.python_version())\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "print('Keras version:', tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "# %reload_ext tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs.\n",
    "!rm -rf logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See available datasets\n",
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset_train_raw, dataset_test_raw), dataset_info = tfds.load(\n",
    "    name='rock_paper_scissors',\n",
    "    data_dir='tmp',\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    "    split=[tfds.Split.TRAIN, tfds.Split.TEST],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Raw train dataset:', dataset_train_raw)\n",
    "print('Raw train dataset size:', len(list(dataset_train_raw)), '\\n')\n",
    "\n",
    "print('Raw test dataset:', dataset_test_raw)\n",
    "print('Raw test dataset size:', len(list(dataset_test_raw)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_EXAMPLES = dataset_info.splits['train'].num_examples\n",
    "NUM_TEST_EXAMPLES = dataset_info.splits['test'].num_examples\n",
    "\n",
    "print('Number of TRAIN examples:', NUM_TRAIN_EXAMPLES);\n",
    "print('Number of TEST examples:', NUM_TEST_EXAMPLES);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMG_SHAPE = dataset_info.features['image'].shape\n",
    "INPUT_IMG_SIZE = dataset_info.features['image'].shape[0]\n",
    "\n",
    "print('Input image shape:', INPUT_IMG_SHAPE)\n",
    "print('Input image size:', INPUT_IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = dataset_info.features['label'].num_classes\n",
    "\n",
    "print('Number of label classes:', NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_name = dataset_info.features['label'].int2str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_label_name(0));\n",
    "print(get_label_name(1));\n",
    "print(get_label_name(2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_dataset(dataset):\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plot_index = 0\n",
    "    for features in dataset.take(12):\n",
    "        (image, label) = features\n",
    "        plot_index += 1\n",
    "        plt.subplot(3, 4, plot_index)\n",
    "        # plt.axis('Off')\n",
    "        label = get_label_name(label.numpy())\n",
    "        plt.title('Label: %s' % label)\n",
    "        plt.imshow(image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore raw training dataset images.\n",
    "preview_dataset(dataset_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore what values are used to represent the image. \n",
    "(first_image, first_lable) = list(dataset_train_raw.take(1))[0]\n",
    "print('Label:', first_lable.numpy(), '\\n')\n",
    "print('Image shape:', first_image.numpy().shape, '\\n')\n",
    "print(first_image.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(image, label):\n",
    "    # Make image color values to be float.\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Make image color values to be in [0..1] range.\n",
    "    image = image / 255.\n",
    "    # Make sure that image has a right size\n",
    "    image = tf.image.resize(image, [INPUT_IMG_SIZE, INPUT_IMG_SIZE])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train_raw.map(format_example)\n",
    "dataset_test = dataset_test_raw.map(format_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore what values are used to represent the image. \n",
    "(first_image, first_lable) = list(dataset_train.take(1))[0]\n",
    "print('Label:', first_lable.numpy(), '\\n')\n",
    "print('Image shape:', first_image.numpy().shape, '\\n')\n",
    "print(first_image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore preprocessed training dataset images.\n",
    "preview_dataset(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(image, label):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    # image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_contrast(image, lower=0.5, upper=1.0)\n",
    "    # image = tf.image.random_saturation(image, lower=0.5, upper=1.0)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_augmented = dataset_train.map(augment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore augmented training dataset.\n",
    "preview_dataset(dataset_train_augmented)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data shuffling and batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataset_train_augmented_shuffled = dataset_train_augmented.shuffle(\n",
    "    buffer_size=NUM_TRAIN_EXAMPLES\n",
    ")\n",
    "\n",
    "dataset_train_augmented_shuffled = dataset_train_augmented.batch(\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Prefetch will enable the input pipeline to asynchronously fetch batches while your model is training.\n",
    "dataset_train_augmented_shuffled = dataset_train_augmented_shuffled.prefetch(\n",
    "    buffer_size=tf.data.experimental.AUTOTUNE\n",
    ")\n",
    "\n",
    "dataset_test_shuffled = dataset_test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_train_augmented_shuffled)\n",
    "print(dataset_test_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging the batches using conversion to Numpy arrays.\n",
    "batches = tfds.as_numpy(dataset_train_augmented_shuffled)\n",
    "for batch in batches:\n",
    "    image_batch, label_batch = batch\n",
    "    print('Label batch shape:', label_batch.shape, '\\n')\n",
    "    print('Image batch shape:', image_batch.shape, '\\n')\n",
    "    print('Label batch:', label_batch, '\\n')\n",
    "    \n",
    "    for batch_item_index in range(len(image_batch)):\n",
    "        print('First batch image:', image_batch[batch_item_index], '\\n')\n",
    "        plt.imshow(image_batch[batch_item_index])\n",
    "        plt.show()\n",
    "        # Break to shorten the output.\n",
    "        break\n",
    "    # Break to shorten the output.\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# First convolution.\n",
    "model.add(tf.keras.layers.Convolution2D(\n",
    "    input_shape=INPUT_IMG_SHAPE,\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    activation=tf.keras.activations.relu\n",
    "))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=(2, 2)\n",
    "))\n",
    "\n",
    "# Second convolution.\n",
    "model.add(tf.keras.layers.Convolution2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    activation=tf.keras.activations.relu\n",
    "))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=(2, 2)\n",
    "))\n",
    "\n",
    "# Third convolution.\n",
    "model.add(tf.keras.layers.Convolution2D(\n",
    "    filters=64,\n",
    "    kernel_size=3,\n",
    "    activation=tf.keras.activations.relu\n",
    "))\n",
    "model.add(tf.keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=(2, 2)\n",
    "))\n",
    "\n",
    "# Flatten the results to feed into DNN.\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# 64 neuron hidden layer\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=64,\n",
    "    activation=tf.keras.activations.relu\n",
    "))\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=NUM_CLASSES,\n",
    "    activation=tf.keras.activations.softmax\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "rmsprop_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=rmsprop_optimizer,\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // BATCH_SIZE\n",
    "validation_steps = NUM_TEST_EXAMPLES // BATCH_SIZE\n",
    "\n",
    "print('steps_per_epoch:', steps_per_epoch)\n",
    "print('validation_steps:', validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing callbacks.\n",
    "os.makedirs('logs/fit', exist_ok=True)\n",
    "tensorboard_log_dir = 'logs/fit/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=tensorboard_log_dir,\n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "os.makedirs('tmp/checkpoints', exist_ok=True)\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='tmp/checkpoints/weights.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    ")\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = model.fit(\n",
    "    x=dataset_train_augmented_shuffled.repeat(),\n",
    "    epochs=5,\n",
    "    validation_data=dataset_test_shuffled.repeat(),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[tensorboard_callback, model_checkpoint_callback, early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(training_history.history['loss'], label='training set')\n",
    "plt.plot(training_history.history['val_loss'], label='test set')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(training_history.history['accuracy'], label='training set')\n",
    "plt.plot(training_history.history['val_accuracy'], label='test set')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging the training with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.laurencemoroney.com/rock-paper-scissors-dataset/\n",
    "\n",
    "https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%208%20-%20Lesson%202%20-%20Notebook%20(RockPaperScissors).ipynb#scrollTo=ZABJp7T3VLCU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
    "dataset = dataset.shuffle(5).batch(2)\n",
    "list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model.fit_generator(\n",
    "    dataset['train'],\n",
    "    epochs=5,\n",
    "    validation_data = dataset['test'],\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laurence version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps.zip -o .tmp/rps.zip\n",
    "!curl https://storage.googleapis.com/laurencemoroney-blog.appspot.com/rps-test-set.zip -o .tmp/rps-test-set.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '.tmp/rps.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('.tmp/')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = '.tmp/rps-test-set.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('.tmp/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rock_dir = os.path.join('.tmp/rps/rock')\n",
    "paper_dir = os.path.join('.tmp/rps/paper')\n",
    "scissors_dir = os.path.join('.tmp/rps/scissors')\n",
    "\n",
    "print('total training rock images:', len(os.listdir(rock_dir)), '\\n')\n",
    "print('total training paper images:', len(os.listdir(paper_dir)), '\\n')\n",
    "print('total training scissors images:', len(os.listdir(scissors_dir)), '\\n')\n",
    "\n",
    "rock_files = os.listdir(rock_dir)\n",
    "print(rock_files[:10], '\\n')\n",
    "\n",
    "paper_files = os.listdir(paper_dir)\n",
    "print(paper_files[:10], '\\n')\n",
    "\n",
    "scissors_files = os.listdir(scissors_dir)\n",
    "print(scissors_files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "pic_index = 2\n",
    "\n",
    "next_rock = [os.path.join(rock_dir, fname) for fname in rock_files[pic_index-2:pic_index]]\n",
    "next_paper = [os.path.join(paper_dir, fname) for fname in paper_files[pic_index-2:pic_index]]\n",
    "next_scissors = [os.path.join(scissors_dir, fname) for fname in scissors_files[pic_index-2:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_rock + next_paper + next_scissors):\n",
    "    # print(img_path)\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('Off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "TRAINING_DIR = '.tmp/rps/'\n",
    "training_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "VALIDATION_DIR = \".tmp/rps-test-set/\"\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    target_size=(150,150),\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_DIR,\n",
    "    target_size=(150,150),\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=5,\n",
    "    validation_data = validation_generator,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('rps.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.plot(epochs, accuracy, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
